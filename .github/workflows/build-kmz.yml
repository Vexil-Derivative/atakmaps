name: Build KMZs and Deploy to Pages

on:
  push:
    branches: [main]
    paths:
      - .github/workflows/build-kmz.yml
  schedule:
    - cron: "0 9 * * 1" # Mondays at 09:00 UTC
  workflow_dispatch: {}
  repository_dispatch:
    types: [build-kmz]

permissions:
  contents: read
  pages: write
  id-token: write
  actions: read

concurrency:
  group: pages
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install GDAL + dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gdal-bin python3-gdal python3-pip zip unzip

      - name: Fetch source data (MVUM + TrailNFS)
        run: |
          set -euo pipefail
          mkdir -p projects/mvum/inputs projects/usfs/inputs

          base_mvum="https://apps.fs.usda.gov/arcx/rest/services/EDW/EDW_MVUM_01/MapServer"
          base_trails="https://apps.fs.usda.gov/arcx/rest/services/EDW/EDW_TrailNFSPublish_01/MapServer"

          # Hash on IDs to detect source changes without storing full data.
          curl -sSf --retry 5 --retry-delay 5 --retry-all-errors "${base_mvum}/1/query?where=1%3D1&returnIdsOnly=true&f=json" -o /tmp/mvum_roads_ids.json
          curl -sSf --retry 5 --retry-delay 5 --retry-all-errors "${base_mvum}/2/query?where=1%3D1&returnIdsOnly=true&f=json" -o /tmp/mvum_trails_ids.json
          curl -sSf --retry 5 --retry-delay 5 --retry-all-errors "${base_trails}/0/query?where=1%3D1&returnIdsOnly=true&f=json" -o /tmp/usfs_trails_ids.json
          hash=$(cat /tmp/mvum_trails_ids.json /tmp/mvum_roads_ids.json /tmp/usfs_trails_ids.json | sha256sum | cut -d' ' -f1)
          echo "INPUT_HASH=${hash}-v2" >> "$GITHUB_ENV"

          fetch_layer() {
            local url_base="$1" layer="$2" dest="$3" name="$4"
            local offset=0 page=0
            rm -f "${dest%.*}".*
            while true; do
              url="${url_base}/${layer}/query?where=1%3D1&outFields=*&returnGeometry=true&outSR=4326&f=geojson&resultOffset=${offset}&resultRecordCount=2000"
              tmp="/tmp/${name}_page_${offset}.geojson"
              curl -sSf --retry 5 --retry-delay 5 --retry-all-errors --max-time 120 "$url" -o "$tmp"
              count=$(python3 - "$tmp" -c "import json,sys; data=json.load(open(sys.argv[1])); print(len(data.get('features', [])))")
              if [ "$count" -eq 0 ]; then break; fi
              if [ "$page" -eq 0 ]; then
                ogr2ogr -overwrite -f "ESRI Shapefile" "$dest" "$tmp"
              else
                ogr2ogr -append -f "ESRI Shapefile" "$dest" "$tmp" -nln "$(basename "$dest" .shp)"
              fi
              exceed=$(python3 - "$tmp" -c "import json,sys; data=json.load(open(sys.argv[1])); print(str(data.get('exceededTransferLimit', False)).lower())")
              if [ "$exceed" != "true" ]; then break; fi
              offset=$((offset+2000))
              page=$((page+1))
            done
          }

          fetch_layer "$base_mvum" 1 projects/mvum/inputs/MVUM_Symbology_-_Motor_Vehicle_Use_Map_Roads.shp mvum_roads
          fetch_layer "$base_mvum" 2 projects/mvum/inputs/MVUM_Symbology_-_Motor_Vehicle_Use_Map_Trails.shp mvum_trails
          fetch_layer "$base_trails" 0 "projects/usfs/inputs/National_Forest_System_Trails_(Feature_Layer).shp" usfs_trails

      - name: Fetch Colorado GMU shapefile
        run: |
          set -euo pipefail
          mkdir -p projects/colorado-hunting/inputs
          url="https://hub.arcgis.com/api/v3/datasets/2c0794ece2ee4c8d9ac1f64cda8d0216_0/downloads/data?format=shp&spatialRefId=3857&where=1%3D1"
          tmp=/tmp/co_gmu.zip
          curl -sSfL --retry 5 --retry-delay 5 --retry-all-errors --max-time 180 "$url" -o "$tmp"
          unzip -o "$tmp" -d projects/colorado-hunting/inputs

      - name: Fetch Colorado COTREX data
        run: |
          set -euo pipefail
          mkdir -p projects/colorado-cotrex/inputs
          url="https://www.arcgis.com/sharing/rest/content/items/cae8ed959b8a4ed48680df62b31eec60/data"
          tmp=/tmp/cotrex.zip
          curl -sSfL --retry 5 --retry-delay 5 --retry-all-errors --max-time 1200 "$url" -o "$tmp"
          unzip -o "$tmp" -d projects/colorado-cotrex/inputs
          # Normalize names if the dataset uses CPW_Trails*; keep original copies.
          base=projects/colorado-cotrex/inputs
          if [ -f "$base/CPW_Trails.shp" ]; then
            cp "$base/CPW_Trails.shp" "$base/COTREX_Trails.shp" || true
            for ext in dbf shx prj cpg xml; do
              if [ -f "$base/CPW_Trails.$ext" ]; then
                cp "$base/CPW_Trails.$ext" "$base/COTREX_Trails.$ext" || true
              fi
            done
          fi
          if [ -f "$base/CPW_Trailheads.shp" ]; then
            cp "$base/CPW_Trailheads.shp" "$base/COTREX_Trailheads.shp" || true
            for ext in dbf shx prj cpg xml; do
              if [ -f "$base/CPW_Trailheads.$ext" ]; then
                cp "$base/CPW_Trailheads.$ext" "$base/COTREX_Trailheads.$ext" || true
              fi
            done
          fi
          ls -l "$base" || true
          if ! ls "$base"/COTREX_Trails.shp "$base"/COTREX_Trailheads.shp >/dev/null 2>&1; then
            echo "COTREX shapefiles not found after download/unzip" >&2
            exit 2
          fi

      - name: Restore cached site for unchanged inputs
        id: cache-site
        uses: actions/cache@v4
        with:
          path: site
          key: kmz-site-${{ env.INPUT_HASH }}

      - name: Build MVUM KMZs
        if: steps.cache-site.outputs.cache-hit != 'true'
        run: python3 projects/mvum/main.py

      - name: Build USFS trails KMZs
        if: steps.cache-site.outputs.cache-hit != 'true'
        run: python3 projects/usfs/main.py

      - name: Build Colorado GMU KMZ
        if: steps.cache-site.outputs.cache-hit != 'true'
        run: python3 projects/colorado-hunting/main.py

      - name: Build Colorado COTREX KMZs
        if: steps.cache-site.outputs.cache-hit != 'true'
        run: python3 projects/colorado-cotrex/main.py

      - name: Collect site artifacts
        if: steps.cache-site.outputs.cache-hit != 'true'
        run: |
          mkdir -p site/mvum site/usfs site/colorado-hunting site/cotrex site/cotrip
          cp -a projects/mvum/outputs/. site/mvum/ || true
          cp -a projects/usfs/outputs/. site/usfs/ || true
          cp -a projects/colorado-hunting/outputs/. site/colorado-hunting/ || true
          cp -a projects/colorado-cotrex/outputs/. site/cotrex/ || true
          cp -a projects/colorado-traffic-cameras/outputs/. site/cotrip/ || true
          find site -type f | sort > site/manifest.txt
          python3 - <<'PY'
          import time
          from pathlib import Path

          root = Path("site")
          manifest = []
          for path in sorted(root.rglob("*")):
              if path.is_file():
                  stat = path.stat()
                  rel = path.relative_to(root)
                  manifest.append((str(rel), stat.st_mtime, stat.st_size))

          def human_size(n):
              for unit in ["B","KB","MB","GB"]:
                  if n < 1024:
                      return f"{n:.1f} {unit}"
                  n /= 1024
              return f"{n:.1f} TB"

          def section(title, predicate):
              rows = [(f, m, s) for f,m,s in manifest if predicate(f)]
              if not rows:
                  return ""
              lines = [f"<h2>{title}</h2>", "<table><tr><th>File</th><th>Last updated (UTC)</th><th>Size</th></tr>"]
              for f, m, s in rows:
                  ts = time.strftime("%Y-%m-%d %H:%M:%S", time.gmtime(m))
                  lines.append(f"<tr><td><a href=\"{f}\">{f}</a></td><td>{ts}</td><td>{human_size(s)}</td></tr>")
              lines.append("</table>")
              return "\n".join(lines)

          body = []
          body.append("<h1>ATAK Maps</h1>")
          body.append(f"<p>Build completed on {time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime())} UTC</p>")
          body.append(section("USFS MVUM", lambda f: f.startswith("mvum/")))
          body.append(section("USFS Trails (non-motorized)", lambda f: f.startswith("usfs/")))
          body.append(section("Colorado GMUs / Land Ownership", lambda f: f.startswith("colorado-hunting/")))
          body.append(section("Colorado COTREX", lambda f: f.startswith("cotrex/")))
          body.append(section("Colorado CoTrip Cameras (CoT packages)", lambda f: f.startswith("cotrip/")))

          html = "\n".join([
              "<!doctype html>",
              "<html><head><meta charset='utf-8'><title>ATAK Maps</title>",
              "<style>body{font-family:Arial, sans-serif;padding:20px;}table{border-collapse:collapse;width:100%;max-width:1100px;}th,td{padding:6px 8px;border:1px solid #ddd;}th{text-align:left;background:#f2f2f2;}tr:nth-child(even){background:#fafafa;}h1,h2{margin-top:24px;}</style>",
              "</head><body>",
              *body,
              "</body></html>"
          ])
          Path("site/index.html").write_text(html, encoding="utf-8")
          PY

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deploy.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deploy
        uses: actions/deploy-pages@v4
